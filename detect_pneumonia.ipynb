{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential # CNN\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "from config import DATASET_PATH\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load data\n",
    "\n",
    "# via : https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data\n",
    "\n",
    "labels = ['NORMAL','PNEUMONIA']\n",
    "img_size = 150 # 150*150px\n"
   ],
   "id": "e23e0993b6c166aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_data(data_dir):\n",
    "    data = list()\n",
    "    \n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_id = labels.index(label) # 'PNEU' = 0, 'NORM' = 1\n",
    "              \n",
    "        for img_name in tqdm(os.listdir(path)):\n",
    "            \n",
    "            try:\n",
    "                # read image\n",
    "                img = cv2.imread(os.path.join(path, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                if img is None:\n",
    "                    print(\"image can not be read\")\n",
    "                    continue\n",
    "                \n",
    "                # resize img\n",
    "                resized_img =  cv2.resize(img, (img_size, img_size))    \n",
    "                \n",
    "                data.append([resized_img, class_id]) \n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    \n",
    "    return np.array(data, dtype = 'object')            \n",
    "        \n",
    "    "
   ],
   "id": "1b257be697995008",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_path = lambda x : os.path.join(DATASET_PATH, x)",
   "id": "9fef800ba67ccec6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train = get_data(get_path('train'))",
   "id": "32174be4cfec13f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test = get_data(get_path('test'))",
   "id": "7bbe235de9098925",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "val = get_data(get_path('val'))",
   "id": "d7a2c6360077b80c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"train : {train.shape}\\ntest : {test.shape}\\nval : {val.shape}\")",
   "id": "3f8cf802d2efe487",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# data visualizition and preproccessing\n",
    "l = ['NORMAL' if i[1] == 0 else 'PNEUMONIA' for i in train]\n",
    "\n",
    "sns.countplot(x=l,palette='Set2')\n"
   ],
   "id": "9fe70a32b4dd3748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_train, y_train = list(), list()\n",
    "x_test, y_test = list(), list()\n",
    "x_val, y_val = list(), list()\n",
    "\n",
    "for feat, label in train:\n",
    "    x_train.append(feat)\n",
    "    y_train.append(label)"
   ],
   "id": "7414917b7e5bbc95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for feat, label in test:\n",
    "    x_test.append(feat)\n",
    "    y_test.append(label)"
   ],
   "id": "2ddb7b92b8e83fc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for feat, label in val:\n",
    "    x_val.append(feat)\n",
    "    y_val.append(label)"
   ],
   "id": "d1c0770f02abf386",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualization\n",
    "plt.figure()\n",
    "idx = 1\n",
    "plt.imshow(train[idx][0], cmap='gray')\n",
    "plt.title(labels[train[idx][1]])"
   ],
   "id": "5a188e523d812df3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "idx = -idx\n",
    "plt.imshow(train[idx][0], cmap='gray')\n",
    "plt.title(labels[train[idx][1]])"
   ],
   "id": "2999e3d66fbde766",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# normalization : [0,255] -> [0,1]\n",
    "\n",
    "x_train = np.array(x_train) / 255\n",
    "x_test = np.array(x_test) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "\n"
   ],
   "id": "650c4ac3879a50ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_train.shape\n",
    "# (5216,150,150) ->(5216,150,150,1) reshape\n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1) # -1 : oto # 5216\n",
    "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
    "x_val = x_val.reshape(-1, img_size, img_size, 1)\n"
   ],
   "id": "5bda14d41bf61e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x_train.shape",
   "id": "cbe9bf2f6ea46a74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)"
   ],
   "id": "56c58298b35ecf6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# data augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                               rotation_range=30,\n",
    "                               zoom_range=0.2,\n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True\n",
    "                               )\n",
    "\n",
    "datagen.fit(x_train)"
   ],
   "id": "339c20bb3d849522",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create deep learning model and train\n",
    "\n",
    "\"\"\"\n",
    "Feature Extraction Block:\n",
    "    (con2d  - Normalization - maxPooling)\n",
    "    (con2d  - dropout- Normalization - maxPooling) # handle overfitting\n",
    "    (con2d  - Normalization - maxPooling)\n",
    "    (con2d  - dropout- Normalization - maxPooling)\n",
    "    (con2d  - dropout- Normalization - maxPooling)\n",
    "    \n",
    "Classification:\n",
    "    flatten- Dense - dropout- Dense (output)\n",
    "    \n",
    "Compiler :     \n",
    "    optimizer(rmsprop), loss(binary_crossentropy), metrics(accuracy)\n",
    "\"\"\"\n",
    "\n",
    "# conv dict\n",
    "\n",
    "conv_params = {\n",
    "    'kernel_size': (3, 3),\n",
    "    'pool_size': (2, 2),\n",
    "    'padding': 'same',\n",
    "    'activation': 'relu',\n",
    "    'conv_strides': 1,\n",
    "    'pool_strides': 2,\n",
    "    'optimizer' : 'rmsprop',\n",
    "    'loss' : 'binary_crossentropy',\n",
    "    'metrics' : ['accuracy'],\n",
    "    'epochs' : 15,\n",
    "    'batch_size' : 32\n",
    "}"
   ],
   "id": "8cdc75cb64c02130",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# alias\n",
    "\n",
    "ks = conv_params['kernel_size']\n",
    "ps = conv_params['pool_size']\n",
    "pad = conv_params['padding']\n",
    "act = conv_params['activation']\n",
    "conv_strides = conv_params['conv_strides']\n",
    "pool_strides = conv_params['pool_strides']\n",
    "optimizer = conv_params['optimizer']\n",
    "loss = conv_params['loss']\n",
    "metrics = conv_params['metrics']\n",
    "num_epoch = conv_params['epochs']\n",
    "batch_size = conv_params['batch_size']\n",
    "\n",
    "# model construction\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st conv block\n",
    "model.add(Conv2D(32, (7,7), strides = conv_strides, padding = pad, activation = act, input_shape = (img_size, img_size, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = ps , strides = pool_strides, padding = pad))\n",
    "\n",
    "# 2nd conv block\n",
    "model.add(Conv2D(64, (5,5), strides = conv_strides, padding = pad, activation = act)) \n",
    "model.add(Dropout(0.1)) \n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = ps , strides = pool_strides, padding = pad))\n",
    "\n",
    "# 3rd conv block\n",
    "model.add(Conv2D(64, ks, strides = conv_strides, padding = pad, activation = act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = ps , strides = pool_strides, padding = pad))\n",
    "\n",
    "# classification block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation = act))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation = 'sigmoid')) # binary classification - output layer\n",
    "\n",
    "model.compile(loss = loss, optimizer = optimizer, metrics = metrics)"
   ],
   "id": "79f3b649d0da57d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:33:23.344213Z",
     "start_time": "2025-01-30T09:33:23.296741Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "4cc8e4ea6ef27d42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 150, 150, 32)      1600      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 150, 150, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 75, 75, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 75, 75, 64)        51264     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 75, 75, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 38, 38, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 38, 38, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 38, 38, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 19, 19, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 23104)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               2957440   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,048,001\n",
      "Trainable params: 3,047,681\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=2, verbose=1,min_lr=1e-6)\n",
    "\n",
    "# train model\n",
    "history = model.fit(datagen.flow(x_train,y_train,batch_size),\n",
    "          epochs = num_epoch,\n",
    "          verbose = 1,\n",
    "          validation_data = datagen.flow(x_test,y_test),\n",
    "          callbacks = [learning_rate_reduction])\n",
    "            "
   ],
   "id": "25a8dc1902671044",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:33:29.160707Z",
     "start_time": "2025-01-30T09:33:28.537932Z"
    }
   },
   "cell_type": "code",
   "source": "model.evaluate(x_test, y_test) # overfitting detected.",
   "id": "d9e2415a34181130",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 13ms/step - loss: 6.4889 - accuracy: 0.6522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.488945960998535, 0.6522436141967773]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
